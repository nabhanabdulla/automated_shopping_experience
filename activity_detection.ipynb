{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_egSpYdo452"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4Da8AeashvTC",
    "outputId": "2ad0b02d-e700-4ccb-c7cb-fb6c18a62114"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aeT0wc-tqp84",
    "outputId": "236d937b-b5b5-429a-b3b3-c312cab5c9a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLabs  MLabs_combined  nabhan_b160502cs.pdf  Projects\n"
     ]
    }
   ],
   "source": [
    "#!ls drive/'My Drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQ20ED8HrCj2"
   },
   "outputs": [],
   "source": [
    "class Object:\n",
    "    def __init__(self):\n",
    "        self.type = 0\n",
    "        self.xtop = 0\n",
    "        self.ytop = 0\n",
    "        self.xbot = 0\n",
    "        self.ybot = 0\n",
    "        self.xres = 0\n",
    "        self.yres = 0\n",
    "        \n",
    "class Image:\n",
    "    def __init__(self):\n",
    "        self.number = ''\n",
    "        self.location = ''\n",
    "        self.objectList = []\n",
    "        self.personList = []\n",
    "        self.labelPath = ''\n",
    "        self.imgPath = ''\n",
    "        self.labelList = []\n",
    "    \n",
    "class Sequence:\n",
    "    def __init__(self):\n",
    "        self.imageDataList = []\n",
    "        self.label = []\n",
    "        self.dirName = ''\n",
    "\n",
    "class Person:\n",
    "    def __init__(self):\n",
    "        self.name = \"\"\n",
    "        self.xtop = 0\n",
    "        self.ytop = 0\n",
    "        self.xbot = 0\n",
    "        self.ybot = 0\n",
    "        self.jointLocations = []\n",
    "        # [nose, neck, Rsho, Relb, Rwri, Lsho, Lelb, Lwri, Rhip, Rkne, Rank, Lhip, Lkne, Lank, Leye, Reye, Lear, Rear, pt19]\n",
    "        # i have taken only 18 locations according to the parse_pickle script.\n",
    "        #access via 2) index location\n",
    "        self.pickedUpItems = []\n",
    "        self.Wallet = 0\n",
    "        self.inBagItems = []\n",
    "\n",
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(data, key=alphanum_key)\n",
    "\n",
    "def calculateDistance(obj1,obj2):\n",
    "    if obj1[0] == -1 or obj1[1] == -1 or obj2[0] == -1 or obj2[1] == -1:\n",
    "        return -1   #return a large distance.\n",
    "    return math.sqrt( pow(obj1[0]-obj2[0],2) + pow(obj1[1]-obj2[1],2))\n",
    "    \n",
    "def calculateCentroid(obj):\n",
    "    lis = []\n",
    "    lis.append((float(obj.xtop) + float(obj.xbot))/2)\n",
    "    lis.append((float(obj.ytop) + float(obj.ybot))/2)\n",
    "    return lis\n",
    "\n",
    "def get_bag_and_other_objects(objects):\n",
    "    bags = []\n",
    "    others = []\n",
    "    for item in objects:\n",
    "        obj = Object()\n",
    "        if type(item) != type(obj):\n",
    "            print(\"function get_bag_and_other_objects: erroneous item type\")\n",
    "            print(type(item))\n",
    "            print(type(obj))\n",
    "        if item.type == 8:\n",
    "            bags.append(item)\n",
    "        else:\n",
    "            others.append(item)\n",
    "    return bags,others\n",
    "    \n",
    "def get_closest_bag(objects,person):\n",
    "    #adds only the closest bag to all the objects and proceeds.\n",
    "    bags, others = get_bag_and_other_objects(objects)\n",
    "    min_dist = 999999999\n",
    "    closest_bag = ''\n",
    "    for item in bags:\n",
    "        ans = calculateDistance(calculateCentroid(item), calculateCentroid(person))\n",
    "        if ans < min_dist:\n",
    "            min_dist = ans\n",
    "            closest_bag = item\n",
    "    if closest_bag == '':\n",
    "        return []\n",
    "    else:\n",
    "        others.append(closest_bag)\n",
    "    return others\n",
    "\n",
    "\n",
    "def fill_in_missing_objects(modobjects):\n",
    "    '''\n",
    "    First finds out the objects in the modobjects and creates a Object instance for\n",
    "    all the object types not present in modobjects\n",
    "    '''\n",
    "    seenobjects= {}\n",
    "    for obj in modobjects:\n",
    "        if (obj.type - 1)  not in seenobjects.keys():\n",
    "            seenobjects[obj.type - 1] = 1\n",
    "    for i in range(8):\n",
    "        if i  not in seenobjects.keys():\n",
    "            nullobj = Object()\n",
    "            nullobj.type= i + 1\n",
    "            modobjects.append(nullobj)\n",
    "            seenobjects[i] = 1\n",
    "    return modobjects\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDdzBLtWrOs4"
   },
   "outputs": [],
   "source": [
    "def generate_person_object_locations_prevframes(sequence):\n",
    "    '''\n",
    "        Process a sequence of image frames and returns (objects, person) pair in each frame for each person in any frame\n",
    "        \n",
    "        Input: Sequence object\n",
    "        Output: Dictionary with keys as person names and values a list of (objects, person) tuples for each frame\n",
    "    '''\n",
    "    person_set = {}\n",
    "    # person_set is a dictionary mapping person name to the list of tuples (object, person) over the past 5 frames.\n",
    "    # person_set[\"karthik\"] = [(objects,person) , (objects,person) ,(objects,person) , (objects,person), (objects,person)]\n",
    "    #there might be missing objects but the person is in all the frames with default values added in.\n",
    "    idx = 0\n",
    "    if len(sequence.imageDataList) != 5:\n",
    "        print(\" Maintain the length of sequence as 5\")\n",
    "        print(sequence.dirName)\n",
    "            \n",
    "    '''\n",
    "        Populates the person_set with (idx, objects, person) triplets\n",
    "        idx - Frame number\n",
    "        objects - List of Object instances(all objects + bag corresponding to the person)\n",
    "        person - Person instance\n",
    "\n",
    "        * Frames in which a person is not present will have its 'objects' list as empty list \n",
    "          for that person \n",
    "\n",
    "    '''\n",
    "    for item in sequence.imageDataList:\n",
    "        idx += 1\n",
    "        objects = item.objectList\n",
    "        persons = item.personList\n",
    "        for person in persons:\n",
    "            objectsmod = get_closest_bag(objects,person)\n",
    "            objectsmod = fill_in_missing_objects(objectsmod)\n",
    "            if person.name in person_set.keys():\n",
    "                lis = person_set[person.name]\n",
    "                last = lis[-1]\n",
    "                previdx = last[0]\n",
    "                # happens if the person wasn't in the initial frames\n",
    "                # add null values for those frames \n",
    "                while previdx != idx-1:\n",
    "                    per = Person()\n",
    "                    per.name = person.name\n",
    "                    lis.append((previdx + 1,[],per))\n",
    "                    previdx += 1\n",
    "                lis.append((idx,objectsmod,person))\n",
    "                person_set[person.name] = lis\n",
    "            else:\n",
    "                lis = []\n",
    "                previdx = 0\n",
    "                # happens if the person wasn't in the initial frames\n",
    "                # add null values for those frames \n",
    "                while previdx != idx-1:\n",
    "                    per = Person()\n",
    "                    per.name = person.name\n",
    "                    lis.append((previdx + 1,[],per))\n",
    "                    previdx += 1\n",
    "                lis.append((idx,objectsmod,person))\n",
    "                person_set[person.name] = lis\n",
    "    # accounts for missing persons in later frames\n",
    "    for item in person_set.keys():\n",
    "        lis = person_set[item]\n",
    "        last = lis[-1]\n",
    "        previdx = last[0]\n",
    "        while previdx <5:\n",
    "            per = Person()\n",
    "            per.name = item\n",
    "            lis.append((previdx + 1,[],per))\n",
    "            previdx += 1\n",
    "    \n",
    "    '''\n",
    "        Repopulate the person_set dictionary with only (objects, person) pairs\n",
    "    '''\n",
    "    # get the (objects, person) pair\n",
    "    for item in person_set.keys():\n",
    "        lis = person_set[item]\n",
    "        newlis = []\n",
    "        for it in lis:\n",
    "            newlis.append( ( it[1] , it[2] ) )\n",
    "        #print(len(newlis))\n",
    "        person_set[item] = newlis\n",
    "        \n",
    "    #also filters with only the bag closest to the person added to the objects corresponding to that person.\n",
    "    # now for each person you have a the set of object locations and pose locations over the past 5 frames.\n",
    "    return person_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DN3J4GfrSy8"
   },
   "outputs": [],
   "source": [
    "def generate_featuremap_lstm(sequence):\n",
    "    '''\n",
    "        Process a sequence of images and returns feature vectors corresponding to each person in any\n",
    "        of the image\n",
    "        \n",
    "        Input:\n",
    "            Sequence object\n",
    "            \n",
    "        Output:\n",
    "            List of (person_name, features) tuple\n",
    "            \n",
    "    '''\n",
    "    #output: generates each feature over a time frame individually.\n",
    "             #feature1 [x x1 x2 x3 x4]\n",
    "             #feature2 [y y1 y2 y3 y4]\n",
    "             # feature here means the locations of objects and joint locations.\n",
    "    person_set = generate_person_object_locations_prevframes(sequence)\n",
    "    feature_list = []\n",
    "    \n",
    "    for item in person_set.keys():\n",
    "        name = item # person name\n",
    "        item = person_set[item] # list of (objects, person)\n",
    "        \n",
    "        # usually 8 objects (1 + 7 objects ) and 18 joint locations == total\n",
    "        features = [] # over frames\n",
    "        \n",
    "        # one each for a frame (we have 5 frames in a sequence)\n",
    "        for i in range(5):\n",
    "            features.append([])\n",
    "            \n",
    "        idx = 0\n",
    "        for frameitem in item:  \n",
    "            '''\n",
    "                frameitem:\n",
    "                    (objects, person)\n",
    "                    \n",
    "                iterating over frames and appending features\n",
    "                features:\n",
    "                    * object location([x, y] coordinate of centroid of bounding box) for objects (8nos-7+1)\n",
    "                    * [x, y] cordinate for each joint location\n",
    "                      \n",
    "                if 'objects' list is empty, add first 8 features i.e, location of\n",
    "                8 objects as [-1, -1]\n",
    "                \n",
    "                if 'person.jointLocations' list is empty, add 18 features i.e, location of\n",
    "                18 joint locations as [-1, -1]\n",
    "                \n",
    "                features list is extended for each frameitem thus giving one large feature list\n",
    "                for a person i.e, 26 * 5 = 130 dimensional feature vector\n",
    "             \n",
    "                >>> features[idx] = []\n",
    "                >>> features[idx].extend([1, 2])\n",
    "                [1, 2]\n",
    "                >>> features[idx].extend([5, 6])\n",
    "                [1, 2, 5, 6]\n",
    "                >>> features[idx].append([7, 8])\n",
    "                [1, 2, 5, 6, [7, 8]]\n",
    "                \n",
    "            ''' \n",
    "            if len(frameitem[0]) == 0:\n",
    "                for i in range(8):\n",
    "                    features[idx].extend([-1, -1])\n",
    "            else:\n",
    "                for obj in frameitem[0]:\n",
    "                    features[idx].extend(calculateCentroid(obj))\n",
    "            \n",
    "            joint_locations = frameitem[1].jointLocations\n",
    "            if len(joint_locations) == 0:\n",
    "                for i in range(8,26):\n",
    "                    features[idx].extend([ -1, -1 ])\n",
    "            else:\n",
    "                j = 0\n",
    "                for i in range(8,26):\n",
    "                    features[idx].extend([ joint_locations[j],joint_locations[j+1] ])    \n",
    "                    j += 2\n",
    "            idx += 1\n",
    "        feature_list.append((name,features))\n",
    "    return feature_list\n",
    "         \n",
    "def generate_data(all_sequences):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for seq in all_sequences:\n",
    "        features = generate_featuremap_lstm(seq)\n",
    "        #print(features)\n",
    "        labels = seq.label\n",
    "        #print(labels)\n",
    "        if(len(labels) == len(features)):\n",
    "            for it in range(0,len(labels)):\n",
    "                #print(len(features[it][1]))\n",
    "                #if len(features[it][1]) == 150: #calculated from the constant value\n",
    "                all_features.append(features[it][1])\n",
    "                all_labels.append(labels[it])\n",
    "    return all_features,all_labels\n",
    "\n",
    "def discretize(labels):\n",
    "    newlabels=[]\n",
    "    for item in labels:\n",
    "        #print(item)\n",
    "        if item == \"picking\":\n",
    "            newlabels.append(0)\n",
    "        elif item == \"placing\":\n",
    "            newlabels.append(1)\n",
    "        elif item == \"cart\":\n",
    "            newlabels.append(2)\n",
    "        elif item == \"idle\":\n",
    "            newlabels.append(3)\n",
    "        else:\n",
    "            print(\"ERROR when discretizing.\")\n",
    "    return newlabels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "Hn_SpaycrXHu",
    "outputId": "4258514f-3ba3-4a24-8722-bcf8e214f7b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Read ERROR len not 41 ', '153.txt')\n",
      "(\"Error: can't find file or read data \", '177.txt')\n",
      "(\"Error: can't find file or read data \", '192.txt')\n",
      "('Read ERROR len not 41 ', '223.txt')\n",
      "('Read ERROR len not 41 ', '224.txt')\n",
      "(\"Error: can't find file or read data \", '252.txt')\n",
      "(\"Error: can't find file or read data \", '248.txt')\n",
      "('Read ERROR len not 41 ', '264.txt')\n",
      "('Read ERROR len not 41 ', '266.txt')\n",
      "('Read ERROR len not 41 ', '259.txt')\n",
      "(\"Error: can't find file or read data \", '260.txt')\n",
      "('Read ERROR len not 41 ', '281.txt')\n",
      "('Read ERROR len not 41 ', '272.txt')\n",
      "(\"Error: can't find file or read data \", '294.txt')\n",
      "('Read ERROR len not 41 ', '295.txt')\n",
      "(\"Error: can't find file or read data \", '297.txt')\n",
      "(\"Error: can't find file or read data \", '289.txt')\n",
      "(\"Error: can't find file or read data \", '290.txt')\n",
      "(\"Error: can't find file or read data \", '292.txt')\n",
      "('Read ERROR len not 41 ', '313.txt')\n",
      "(\"Error: can't find file or read data \", '315.txt')\n",
      "(\"Error: can't find file or read data \", '316.txt')\n",
      "(\"Error: can't find file or read data \", '317.txt')\n",
      "('Read ERROR len not 41 ', '356.txt')\n",
      "('Read ERROR len not 41 ', '349.txt')\n",
      "(\"Error: can't find file or read data \", '368.txt')\n",
      "(\"Error: can't find file or read data \", '369.txt')\n",
      "('Read ERROR len not 41 ', '371.txt')\n",
      "(\"Error: can't find file or read data \", '392.txt')\n",
      "('Read ERROR len not 41 ', '387.txt')\n",
      "('Read ERROR len not 41 ', '413.txt')\n",
      "(\"Error: can't find file or read data \", '407.txt')\n",
      "(\"Error: can't find file or read data \", '408.txt')\n",
      "('Read ERROR len not 41 ', '450.txt')\n",
      "('Read ERROR len not 41 ', '451.txt')\n",
      "(\"Error: can't find file or read data \", '503.txt')\n"
     ]
    }
   ],
   "source": [
    "def loadDir():\n",
    "    all_sequences = []\n",
    "    ##############################################################################################\n",
    "    imagedir = 'activity_rec/mod-data'#'/content/drive/My Drive/MLabs/Project/activity_rec/mod-data/'\n",
    "    labeldir = 'activity_rec/labels'#'/content/drive/My Drive/MLabs/Project/activity_rec/labels'\n",
    "    persondir = 'activity_rec/persondata'#'/content/drive/My Drive/MLabs/Project/activity_rec/persondata'\n",
    "    ###############################################################################################\n",
    "    dirList = sorted_alphanumeric(glob.glob(os.path.join(imagedir, '**')))\n",
    "    if len(dirList) == 0:\n",
    "        print(\"No directories found\")\n",
    "    \n",
    "    # iterate over all the activity detection data folders(5 images + label file)\n",
    "    for directory in dirList:\n",
    "        cursequence = Sequence()\n",
    "        cursequence.dirName = directory\n",
    "        try:\n",
    "            targetlabelfile = directory + \"/label.txt\"\n",
    "            targetlabel = open(targetlabelfile, 'r')\n",
    "        except IOError:\n",
    "            print(\"Error: can\\'t find file or read data from label file\", directory)\n",
    "        tar_labels=[]\n",
    "        for eachline in targetlabel:\n",
    "            eachline = eachline.rstrip('\\n')\n",
    "            tar_labels.append(eachline)\n",
    "        cursequence.label = tar_labels\n",
    "        \n",
    "        imageList = sorted_alphanumeric(glob.glob(os.path.join(directory, '*.jpg')))\n",
    "        num = 0\n",
    "        imgdatalist = []\n",
    "        for image in imageList:\n",
    "            curimage = Image()\n",
    "            \n",
    "            curimage.persons = len(tar_labels)  #REMOVE THIS ONCE YOU GET JOINT LOCATIONS\n",
    "            curimage.path = image\n",
    "            curimage.number = num\n",
    "            num = num + 1  \n",
    "            segments = image.split('/')\n",
    "            imgname = segments[len(segments) - 1]\n",
    "            imgsegments = imgname.split('.')\n",
    "            imgnumber = imgsegments[0]\n",
    "            labelname = imgnumber + \".txt\"\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                location = labeldir +'/'+ labelname\n",
    "                curimage.labelPath = location\n",
    "                labelFile = open(location , 'r')\n",
    "                objects = []\n",
    "                for line in labelFile:\n",
    "                    curobject = Object()\n",
    "                    input_numbers = line.split(' ')\n",
    "                    if len(input_numbers) == 7:\n",
    "                        curobject.type = int(input_numbers[0])\n",
    "                        curobject.xtop = int(input_numbers[1])\n",
    "                        curobject.ytop = int(input_numbers[2])\n",
    "                        curobject.xbot = int(input_numbers[3])\n",
    "                        curobject.ybot = int(input_numbers[4])\n",
    "                        curobject.xres = int(input_numbers[5])\n",
    "                        curobject.yres = int(input_numbers[6])\n",
    "                    else:\n",
    "                        print(\"Read ERROR len not 7 \" , labelname)\n",
    "                    objects.append(curobject)\n",
    "                curimage.objectList = objects\n",
    "            except IOError:\n",
    "               print(\"Error: can\\'t find file or read data\")\n",
    "            \n",
    "            \n",
    "            persons = []\n",
    "            #write code to get the joint locations\n",
    "            try:\n",
    "                location = persondir +'/'+ labelname\n",
    "                personFile = open(location , 'r')\n",
    "                for line in personFile:\n",
    "                    curperson= Person()\n",
    "                    input_numbers = line.split(' ')\n",
    "                    #print( input_numbers)\n",
    "                    if len(input_numbers) == 42:   #as it inlcudes '\\n' at the end. usually its 41\n",
    "                        curperson.name = input_numbers[0]\n",
    "                        curperson.xtop = int(input_numbers[1])\n",
    "                        curperson.ytop = int(input_numbers[2])\n",
    "                        curperson.xbot = int(input_numbers[3])\n",
    "                        curperson.ybot = int(input_numbers[4])\n",
    "                        for idx in range(5,41):\n",
    "                            curperson.jointLocations.append(int(input_numbers[idx]))\n",
    "                    else:\n",
    "                        print(\"Read ERROR len not 41 \" , labelname)\n",
    "                    persons.append(curperson)\n",
    "                curimage.personList = persons\n",
    "            except IOError:\n",
    "               print(\"Error: can\\'t find file or read data \" , labelname)\n",
    "            \n",
    "            imgdatalist.append(curimage)\n",
    "        cursequence.imageDataList = imgdatalist    \n",
    "        all_sequences.append(cursequence)\n",
    "    return all_sequences\n",
    "        \n",
    "sequences = loadDir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gP8eOwXlwyFX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iccj9_4IrbHR",
    "outputId": "3311a958-c568-4bde-f01b-eea1a6eb43d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f06025677d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "def convert_to_lstm_format(all_features):\n",
    "        npfeatures = array(all_features) \t\n",
    "        features = npfeatures.reshape(len(all_features), 5, 52)\n",
    "        print(features.shape)\n",
    "        return npfeatures      \n",
    "\n",
    "def normalize_time_series(all_features):\n",
    "    new_list = []\n",
    "\n",
    "    #normalization\n",
    "    for item in all_features:\n",
    "        for item2 in item:\n",
    "            new_list.append(item2)\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler  \n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    all_features_scaled = scaler.fit_transform(new_list)  \n",
    "    \n",
    "    final_list = []\n",
    "    lis= []\n",
    "    #converting back to time series\n",
    "    for idx in range(len(all_features_scaled)):\n",
    "        lis.append(all_features_scaled[idx])\n",
    "        if (idx + 1) % 5 ==0:\n",
    "            final_list.append(lis)\n",
    "            lis=[]\n",
    "    return final_list\n",
    "\n",
    "\n",
    "def fit_model(train_X, train_Y, no_of_frames = 5):\t\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(no_of_frames,52)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(train_X, train_Y, epochs=150, batch_size=5, verbose=False)#verbose=2)   \n",
    "    return(model)\n",
    "    \n",
    "def train_model(train_d,train_l):\n",
    "    model = fit_model(train_d, train_l)\n",
    "    ####################################################################################################\n",
    "    model.save('activity_rec/act_rec_lstm.h5')#('/content/drive/My Drive/MLabs/Project/activity-recognition/activity_rec/act_rec_lstm.h5')\n",
    "    ####################################################################################################\n",
    "    return model\n",
    "\n",
    "def load_trained_model():\n",
    "    ######################################################################################\n",
    "    model = load_model('77.h5')#('/content/drive/My Drive/MLabs/Project/activity-recognition/77.h5')\n",
    "    ######################################################################################\n",
    "    return model\n",
    "\n",
    "def to_categorical_tensor( x, n_cls ) :\n",
    "      y = keras.utils.to_categorical( x, num_classes = n_cls )\n",
    "      return y\n",
    "    \n",
    "load_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "ksq80pu1rr1I",
    "outputId": "e8b8519a-3759-43f5-a6b8-9e88c2783a18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Read ERROR len not 41 ', '153.txt')\n",
      "(\"Error: can't find file or read data \", '177.txt')\n",
      "(\"Error: can't find file or read data \", '192.txt')\n",
      "('Read ERROR len not 41 ', '223.txt')\n",
      "('Read ERROR len not 41 ', '224.txt')\n",
      "(\"Error: can't find file or read data \", '252.txt')\n",
      "(\"Error: can't find file or read data \", '248.txt')\n",
      "('Read ERROR len not 41 ', '264.txt')\n",
      "('Read ERROR len not 41 ', '266.txt')\n",
      "('Read ERROR len not 41 ', '259.txt')\n",
      "(\"Error: can't find file or read data \", '260.txt')\n",
      "('Read ERROR len not 41 ', '281.txt')\n",
      "('Read ERROR len not 41 ', '272.txt')\n",
      "(\"Error: can't find file or read data \", '294.txt')\n",
      "('Read ERROR len not 41 ', '295.txt')\n",
      "(\"Error: can't find file or read data \", '297.txt')\n",
      "(\"Error: can't find file or read data \", '289.txt')\n",
      "(\"Error: can't find file or read data \", '290.txt')\n",
      "(\"Error: can't find file or read data \", '292.txt')\n",
      "('Read ERROR len not 41 ', '313.txt')\n",
      "(\"Error: can't find file or read data \", '315.txt')\n",
      "(\"Error: can't find file or read data \", '316.txt')\n",
      "(\"Error: can't find file or read data \", '317.txt')\n",
      "('Read ERROR len not 41 ', '356.txt')\n",
      "('Read ERROR len not 41 ', '349.txt')\n",
      "(\"Error: can't find file or read data \", '368.txt')\n",
      "(\"Error: can't find file or read data \", '369.txt')\n",
      "('Read ERROR len not 41 ', '371.txt')\n",
      "(\"Error: can't find file or read data \", '392.txt')\n",
      "('Read ERROR len not 41 ', '387.txt')\n",
      "('Read ERROR len not 41 ', '413.txt')\n",
      "(\"Error: can't find file or read data \", '407.txt')\n",
      "(\"Error: can't find file or read data \", '408.txt')\n",
      "('Read ERROR len not 41 ', '450.txt')\n",
      "('Read ERROR len not 41 ', '451.txt')\n",
      "(\"Error: can't find file or read data \", '503.txt')\n"
     ]
    }
   ],
   "source": [
    "all_sequences = loadDir()   \n",
    "all_features, all_labels = generate_data(all_sequences)\n",
    "all_features = normalize_time_series(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "RNb9okB639IA",
    "outputId": "8e394002-0059-4115-a62e-7ff072aa52ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "(28, 5, 52)\n",
      "(10, 5, 52)\n",
      "done\n",
      "(28, 5, 52)\n",
      "(10, 5, 52)\n",
      "done\n",
      "(29, 5, 52)\n",
      "(9, 5, 52)\n",
      "done\n",
      "(29, 5, 52)\n",
      "(9, 5, 52)\n",
      "42.22222343087196\n",
      "[[4 4 7 0]\n",
      " [4 4 1 0]\n",
      " [6 0 8 0]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "def train_test_split(features, labels):\n",
    "    data = features\n",
    "    labels = np.asarray(discretize(labels))\n",
    "    kf = KFold(n_splits=4,shuffle=True)\n",
    "    conf_mat=np.full((4,4),0)\n",
    "    scores=[]\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_d = []\n",
    "        train_l = []\n",
    "        test_d = []\n",
    "        test_l = []\n",
    "        for it in range(0,len(features)):\n",
    "            if it in train_index:\n",
    "                train_d.append(features[it])\n",
    "                train_l.append(labels[it])\n",
    "            if it in test_index:\n",
    "                test_d.append(features[it])\n",
    "                test_l.append(labels[it])\n",
    "        print(\"done\")\n",
    "\n",
    "        train_d = convert_to_lstm_format(train_d)\n",
    "        test_d = convert_to_lstm_format(test_d)\n",
    "\n",
    "        ##one hot encoding must be performed before\n",
    "        train_l = to_categorical_tensor(train_l,4)\n",
    "        test_l = to_categorical_tensor(test_l,4)        \n",
    "        ##training\n",
    "        #print(test_l,train_l)\n",
    "        model = train_model(train_d, train_l)\n",
    "        ## dont train\n",
    "        #model =load_trained_model()\n",
    "        # fit network\n",
    "\t\n",
    "    \t# evaluate model\n",
    "        test_pred = model.predict(test_d)\n",
    "        \n",
    "        '''\n",
    "          when any of the labels aren't in the test data, the confusion_matrix will\n",
    "          be 3x3, whereas we require all the confusion matrices to be 4x4\n",
    "          * check which label is missing\n",
    "        '''\n",
    "        def get_missing_label_indices():\n",
    "          label_indices = [i for i in range(4)]\n",
    "          # get the indices present in test_l or test_pred\n",
    "          test_indices = list(set(np.concatenate([test_l.argmax(axis=1), test_pred.argmax(axis=1)] )))\n",
    "          for index in test_indices:\n",
    "            label_indices.remove(index)\n",
    "          \n",
    "          return label_indices\n",
    "        \n",
    "        cur_matrix = confusion_matrix(test_l.argmax(axis=1), test_pred.argmax(axis=1))\n",
    "        \n",
    "        missing_label_indices = get_missing_label_indices()\n",
    "        \n",
    "        #print('original cur_matrix', '\\n', cur_matrix)\n",
    "        if(len(missing_label_indices) != 0):\n",
    "          for index in missing_label_indices:\n",
    "            # add new zero row at index position(add zeros to columns at index position)\n",
    "            cur_matrix = np.insert(cur_matrix, index, np.zeros(cur_matrix.shape[1]), 0)\n",
    "            # add new zero column at index position\n",
    "            cur_matrix = np.insert(cur_matrix, index, np.zeros(cur_matrix.shape[0]), 1)\n",
    "          \n",
    "        #print('constructed cur_matrix', '\\n', cur_matrix)\n",
    "        '''\n",
    "        print(train_d.shape, train_l.shape)\n",
    "        print(train_l, '\\n', test_l, '\\n')\n",
    "\n",
    "        print(test_l.shape, type(test_l))\n",
    "        '''\n",
    "        conf_mat=np.add(conf_mat, cur_matrix)\n",
    "        \n",
    "        #print(cur_matrix)\n",
    "        _,accuracytrain = model.evaluate(train_d, train_l, batch_size=20, verbose=False)#, verbose=2)\n",
    "        _,accuracytest = model.evaluate(test_d, test_l, batch_size=20, verbose=False)#, verbose=2)\n",
    "        #print(accuracytrain, accuracytest)\n",
    "        scores.append(accuracytest*100)\n",
    "    scores=np.asarray(scores)    \n",
    "    print(scores.mean())\n",
    "    print(conf_mat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_test_split(all_features, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "lgm-xh_Srde0",
    "outputId": "32259eb3-4ffe-41c9-9525-bd6ea9c56d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 3]\n",
      " [0 2 0]\n",
      " [1 0 1]]\n",
      "[[1 0 0 3]\n",
      " [0 0 0 0]\n",
      " [0 0 2 0]\n",
      " [1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "l = [0, 3, 2, 0, 2, 0, 0, 3]\n",
    "pred = [3, 0, 2, 0, 2, 3, 3, 3]\n",
    "def get_missing_label_indices():\n",
    "          label_indices = [i for i in range(4)]\n",
    "          # get the indices present in test_l or test_pred\n",
    "          test_indices = list(set(np.concatenate([l, pred] )))\n",
    "          for index in test_indices:\n",
    "            label_indices.remove(index)\n",
    "          \n",
    "          return label_indices\n",
    "missing_label_indices = get_missing_label_indices() \n",
    "cur_matrix = confusion_matrix(l, pred)\n",
    "print(cur_matrix)\n",
    "if(len(missing_label_indices) != 0):\n",
    "          for index in missing_label_indices:\n",
    "            # add new zero row at index position(add zeros to columns at index position)\n",
    "            cur_matrix = np.insert(cur_matrix, index, np.zeros(cur_matrix.shape[1]), 0)\n",
    "            # add new zero column at index position\n",
    "            cur_matrix = np.insert(cur_matrix, index, np.zeros(cur_matrix.shape[0]), 1)\n",
    "print(cur_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OcH7A7evaG8Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of activity_detection.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
